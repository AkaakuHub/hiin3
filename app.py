import streamlit as st
import numpy as np
import cv2
import mediapipe as mp
from scipy.spatial import procrustes
from streamlit_image_coordinates import streamlit_image_coordinates
from PIL import Image

@st.cache_resource
def initialize_face_landmarker():
    BaseOptions = mp.tasks.BaseOptions
    FaceLandmarker = mp.tasks.vision.FaceLandmarker
    FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions
    VisionRunningMode = mp.tasks.vision.RunningMode
    
    options = FaceLandmarkerOptions(
        base_options=BaseOptions(model_asset_path='face_landmarker_v2_with_blendshapes.task'),
        running_mode=VisionRunningMode.IMAGE
    )
    return FaceLandmarker.create_from_options(options)

def extract_landmarks(image, landmarker):
    try:
        # ç”»åƒãŒRGBã®å ´åˆã¯ãã®ã¾ã¾ä½¿ç”¨ã€BGRã®å ´åˆã¯å¤‰æ›
        if len(image.shape) == 3 and image.shape[2] == 3:
            # RGBã¨ä»®å®šã—ã¦å‡¦ç†
            image_rgb = image.copy()
        else:
            st.error(f"ç”»åƒå½¢çŠ¶ãŒäºˆæœŸã—ãªã„å½¢å¼ã§ã™: {image.shape}")
            return None, "ç”»åƒå½¢çŠ¶ã‚¨ãƒ©ãƒ¼"
        
        # ãƒ‡ãƒ¼ã‚¿å‹ã‚’uint8ã«ç¢ºå®Ÿã«å¤‰æ›
        if image_rgb.dtype != np.uint8:
            image_rgb = (image_rgb * 255).astype(np.uint8) if image_rgb.max() <= 1.0 else image_rgb.astype(np.uint8)
        
        # ç”»åƒãŒé€£ç¶šé…åˆ—ã§ã‚ã‚‹ã“ã¨ã‚’ä¿è¨¼
        image_rgb = np.ascontiguousarray(image_rgb)
        
        st.write(f"ãƒ‡ãƒãƒƒã‚°: ç”»åƒå½¢çŠ¶={image_rgb.shape}, ãƒ‡ãƒ¼ã‚¿å‹={image_rgb.dtype}, æœ€å¤§å€¤={image_rgb.max()}, æœ€å°å€¤={image_rgb.min()}")
        
        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image_rgb)
        result = landmarker.detect(mp_image)
        
        if result.face_landmarks and len(result.face_landmarks) > 0:
            landmarks = result.face_landmarks[0]
            points = np.array([[lm.x * image.shape[1], lm.y * image.shape[0], lm.z] for lm in landmarks])
            st.success(f"é¡”ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ¤œå‡ºæˆåŠŸ: {len(landmarks)}å€‹ã®ç‚¹")
            return points, None
        else:
            return None, f"é¡”ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚æ¤œå‡ºã•ã‚ŒãŸé¡”ã®æ•°: {len(result.face_landmarks) if result.face_landmarks else 0}"
    
    except Exception as e:
        st.error(f"ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æŠ½å‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None, f"ã‚¨ãƒ©ãƒ¼: {str(e)}"

def calculate_procrustes_similarity(landmarks1, landmarks2):
    mtx1, mtx2, disparity = procrustes(landmarks1, landmarks2)
    return disparity

def draw_landmarks_on_image(image, landmarks):
    if landmarks is None:
        return image
    
    annotated_image = image.copy()
    height, width = image.shape[:2]
    
    # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®ã‚µã‚¤ã‚ºã‚’ç”»åƒã‚µã‚¤ã‚ºã«å¿œã˜ã¦èª¿æ•´
    point_size = max(1, min(width, height) // 200)
    
    # MediaPipeã®é¡”ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ¥ç¶šæƒ…å ±ï¼ˆä¸»è¦ãªé¡”ã®è¼ªéƒ­ï¼‰
    connections = [
        # é¡”ã®è¼ªéƒ­ (0-16)
        [(i, i+1) for i in range(16)],
        # å·¦çœ‰æ¯› (17-21)
        [(i, i+1) for i in range(17, 21)],
        # å³çœ‰æ¯› (22-26)
        [(i, i+1) for i in range(22, 26)],
        # é¼»ç­‹ (27-30)
        [(i, i+1) for i in range(27, 30)],
        # é¼»ã®ä¸‹éƒ¨ (31-35)
        [(i, i+1) for i in range(31, 35)],
        # å·¦ç›® (36-41)
        [(i, i+1) for i in range(36, 41)] + [(41, 36)],
        # å³ç›® (42-47)
        [(i, i+1) for i in range(42, 47)] + [(47, 42)],
        # å¤–å”‡ (48-59)
        [(i, i+1) for i in range(48, 59)] + [(59, 48)],
        # å†…å”‡ (60-67)
        [(i, i+1) for i in range(60, 67)] + [(67, 60)]
    ]
    
    # ç·šã‚’æç”»ï¼ˆMediaPipeã®å…¨478ç‚¹ã§ã¯è¤‡é›‘ã™ãã‚‹ã®ã§ã€ä¸»è¦ãª68ç‚¹ã®ã¿è¡¨ç¤ºï¼‰
    if len(landmarks) >= 68:
        for connection_group in connections:
            for start_idx, end_idx in connection_group:
                if start_idx < len(landmarks) and end_idx < len(landmarks):
                    start_point = (int(landmarks[start_idx][0]), int(landmarks[start_idx][1]))
                    end_point = (int(landmarks[end_idx][0]), int(landmarks[end_idx][1]))
                    cv2.line(annotated_image, start_point, end_point, (0, 255, 255), 1)
    
    # å…¨ãƒã‚¤ãƒ³ãƒˆã‚’æç”»
    for i, point in enumerate(landmarks):
        x, y = int(point[0]), int(point[1])
        
        # é‡è¦ãªãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã¯å¤§ããè¡¨ç¤º
        if i < 68:  # ä¸»è¦ãª68ç‚¹
            if i in [36, 39, 42, 45]:  # ç›®ã®è§’
                cv2.circle(annotated_image, (x, y), point_size + 1, (255, 0, 0), -1)  # é’
            elif i in [48, 54]:  # å£ã®è§’
                cv2.circle(annotated_image, (x, y), point_size + 1, (0, 0, 255), -1)  # èµ¤
            elif i in [30]:  # é¼»ã®å…ˆç«¯
                cv2.circle(annotated_image, (x, y), point_size + 1, (255, 255, 0), -1)  # ã‚·ã‚¢ãƒ³
            else:
                cv2.circle(annotated_image, (x, y), point_size, (0, 255, 0), -1)  # ç·‘
        else:  # ãã®ä»–ã®è©³ç´°ãƒã‚¤ãƒ³ãƒˆ
            cv2.circle(annotated_image, (x, y), max(1, point_size // 2), (0, 255, 0), -1)  # å°ã•ã„ç·‘
    
    # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ•°ã‚’ç”»åƒã«è¡¨ç¤º
    cv2.putText(annotated_image, f"Points: {len(landmarks)}", 
                (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    
    return annotated_image

def main():
    st.set_page_config(page_title="é¡”å½¢çŠ¶é¡ä¼¼åº¦åˆ†æã‚¢ãƒ—ãƒª", layout="wide")
    st.title("é¡”å½¢çŠ¶é¡ä¼¼åº¦åˆ†æã‚¢ãƒ—ãƒª")
    
    mode = st.sidebar.selectbox("ãƒ¢ãƒ¼ãƒ‰é¸æŠ", ["è‡ªå‹•è§£æãƒ¢ãƒ¼ãƒ‰", "æ‰‹å‹•æ³¨é‡ˆãƒ¢ãƒ¼ãƒ‰"])
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.subheader("åŸºæº–ç”»åƒ")
        uploaded_base = st.file_uploader("åŸºæº–ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['jpg', 'jpeg', 'png'], key="base")
    
    with col2:
        st.subheader("æ¯”è¼ƒç”»åƒ1")
        uploaded_comp1 = st.file_uploader("æ¯”è¼ƒç”»åƒ1ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['jpg', 'jpeg', 'png'], key="comp1")
    
    with col3:
        st.subheader("æ¯”è¼ƒç”»åƒ2")
        uploaded_comp2 = st.file_uploader("æ¯”è¼ƒç”»åƒ2ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['jpg', 'jpeg', 'png'], key="comp2")
    
    if mode == "è‡ªå‹•è§£æãƒ¢ãƒ¼ãƒ‰":
        auto_analysis_mode(uploaded_base, uploaded_comp1, uploaded_comp2, col1, col2, col3)
    else:
        manual_annotation_mode(uploaded_base, uploaded_comp1, uploaded_comp2, col1, col2, col3)

def auto_analysis_mode(uploaded_base, uploaded_comp1, uploaded_comp2, col1, col2, col3):
    if uploaded_base and uploaded_comp1 and uploaded_comp2:
        landmarker = initialize_face_landmarker()
        
        st.info("ç”»åƒã‚’å‡¦ç†ä¸­...")
        
        base_image = np.array(Image.open(uploaded_base).convert('RGB'))
        comp1_image = np.array(Image.open(uploaded_comp1).convert('RGB'))
        comp2_image = np.array(Image.open(uploaded_comp2).convert('RGB'))
        
        st.write("### ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æŠ½å‡ºçµæœ")
        
        st.write("**åŸºæº–ç”»åƒã®å‡¦ç†:**")
        base_landmarks, base_error = extract_landmarks(base_image, landmarker)
        
        st.write("**æ¯”è¼ƒç”»åƒ1ã®å‡¦ç†:**")
        comp1_landmarks, comp1_error = extract_landmarks(comp1_image, landmarker)
        
        st.write("**æ¯”è¼ƒç”»åƒ2ã®å‡¦ç†:**")
        comp2_landmarks, comp2_error = extract_landmarks(comp2_image, landmarker)
        
        # ã‚¨ãƒ©ãƒ¼è¡¨ç¤º
        errors = []
        if base_error:
            errors.append(f"åŸºæº–ç”»åƒ: {base_error}")
        if comp1_error:
            errors.append(f"æ¯”è¼ƒç”»åƒ1: {comp1_error}")
        if comp2_error:
            errors.append(f"æ¯”è¼ƒç”»åƒ2: {comp2_error}")
        
        if errors:
            st.error("ä»¥ä¸‹ã®ç”»åƒã§å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ:")
            for error in errors:
                st.write(f"- {error}")
        
        if base_landmarks is not None and comp1_landmarks is not None and comp2_landmarks is not None:
            # ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ä»˜ãç”»åƒã‚’ç”Ÿæˆ
            base_annotated = draw_landmarks_on_image(base_image, base_landmarks)
            comp1_annotated = draw_landmarks_on_image(comp1_image, comp1_landmarks)
            comp2_annotated = draw_landmarks_on_image(comp2_image, comp2_landmarks)
            
            # å…ƒç”»åƒã¨ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”»åƒã‚’è¡¨ç¤º
            st.subheader("ğŸ” é¡”ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ¤œå‡ºçµæœ")
            
            with col1:
                st.write("**åŸºæº–ç”»åƒ**")
                st.image(base_image, caption="å…ƒç”»åƒ", use_container_width=True)
                st.image(base_annotated, caption="ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ¤œå‡ºçµæœ", use_container_width=True)
            
            with col2:
                st.write("**æ¯”è¼ƒç”»åƒ1**")
                st.image(comp1_image, caption="å…ƒç”»åƒ", use_container_width=True)
                st.image(comp1_annotated, caption="ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ¤œå‡ºçµæœ", use_container_width=True)
            
            with col3:
                st.write("**æ¯”è¼ƒç”»åƒ2**")
                st.image(comp2_image, caption="å…ƒç”»åƒ", use_container_width=True)
                st.image(comp2_annotated, caption="ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ¤œå‡ºçµæœ", use_container_width=True)
            
            # é¡ä¼¼åº¦è¨ˆç®—
            similarity1 = calculate_procrustes_similarity(base_landmarks, comp1_landmarks)
            similarity2 = calculate_procrustes_similarity(base_landmarks, comp2_landmarks)
            
            # çµæœè¡¨ç¤ºã‚»ã‚¯ã‚·ãƒ§ãƒ³
            st.markdown("---")
            st.subheader("ğŸ“Š é¡ä¼¼åº¦åˆ†æçµæœ")
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
            col_metric1, col_metric2, col_metric3 = st.columns(3)
            
            with col_metric1:
                st.metric(
                    label="åŸºæº– vs æ¯”è¼ƒ1", 
                    value=f"{similarity1:.4f}",
                    delta=None,
                    help="ãƒ—ãƒ­ã‚¯ãƒ©ã‚¹ãƒ†ã‚¹ä¸ä¸€è‡´åº¦ï¼ˆå€¤ãŒå°ã•ã„ã»ã©é¡ä¼¼ï¼‰"
                )
            
            with col_metric2:
                st.metric(
                    label="åŸºæº– vs æ¯”è¼ƒ2", 
                    value=f"{similarity2:.4f}",
                    delta=None,
                    help="ãƒ—ãƒ­ã‚¯ãƒ©ã‚¹ãƒ†ã‚¹ä¸ä¸€è‡´åº¦ï¼ˆå€¤ãŒå°ã•ã„ã»ã©é¡ä¼¼ï¼‰"
                )
            
            with col_metric3:
                difference = abs(similarity1 - similarity2)
                st.metric(
                    label="é¡ä¼¼åº¦ã®å·®", 
                    value=f"{difference:.4f}",
                    delta=None,
                    help="2ã¤ã®é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ã®å·®"
                )
            
            # 4æšä¸¦åˆ—æ¯”è¼ƒè¡¨ç¤º
            st.subheader("ğŸ” è©³ç´°æ¯”è¼ƒ")
            
            # ã‚ˆã‚Šæ˜ç¢ºãªçµæœè¡¨ç¤º
            if similarity1 < similarity2:
                winner = "æ¯”è¼ƒç”»åƒ1"
                winner_score = similarity1
                loser = "æ¯”è¼ƒç”»åƒ2"
                loser_score = similarity2
                st.success(f"ğŸ† **{winner}** ã®æ–¹ãŒåŸºæº–ç”»åƒã«ã‚ˆã‚Šé¡ä¼¼ã—ã¦ã„ã¾ã™ï¼ˆã‚¹ã‚³ã‚¢å·®: {difference:.4f}ï¼‰")
            else:
                winner = "æ¯”è¼ƒç”»åƒ2"
                winner_score = similarity2
                loser = "æ¯”è¼ƒç”»åƒ1"
                loser_score = similarity1
                st.success(f"ğŸ† **{winner}** ã®æ–¹ãŒåŸºæº–ç”»åƒã«ã‚ˆã‚Šé¡ä¼¼ã—ã¦ã„ã¾ã™ï¼ˆã‚¹ã‚³ã‚¢å·®: {difference:.4f}ï¼‰")
            
            # 4æšç”»åƒã®ä¸¦åˆ—è¡¨ç¤º
            col_comp1, col_comp2, col_comp3, col_comp4 = st.columns(4)
            
            with col_comp1:
                st.write("**åŸºæº–ç”»åƒ**")
                st.image(base_annotated, caption="åŸºæº–", use_container_width=True)
            
            with col_comp2:
                st.write("**æ¯”è¼ƒç”»åƒ1**")
                border_color = "green" if winner == "æ¯”è¼ƒç”»åƒ1" else "red"
                st.image(comp1_annotated, caption=f"é¡ä¼¼åº¦: {similarity1:.4f}", use_container_width=True)
                if winner == "æ¯”è¼ƒç”»åƒ1":
                    st.success("âœ… ã‚ˆã‚Šé¡ä¼¼")
                else:
                    st.info("ğŸ“Š é¡ä¼¼åº¦ä½")
            
            with col_comp3:
                st.write("**æ¯”è¼ƒç”»åƒ2**")
                st.image(comp2_annotated, caption=f"é¡ä¼¼åº¦: {similarity2:.4f}", use_container_width=True)
                if winner == "æ¯”è¼ƒç”»åƒ2":
                    st.success("âœ… ã‚ˆã‚Šé¡ä¼¼")
                else:
                    st.info("ğŸ“Š é¡ä¼¼åº¦ä½")
            
            with col_comp4:
                st.write("**çµæœã‚µãƒãƒªãƒ¼**")
                st.write("**ğŸ† å‹è€…:**")
                st.write(f"{winner}")
                st.write(f"ã‚¹ã‚³ã‚¢: {winner_score:.4f}")
                st.write("")
                st.write("**ğŸ“ˆ è©³ç´°:**")
                st.write(f"æ¤œå‡ºç‚¹æ•°: {len(base_landmarks)}ç‚¹")
                st.write(f"å‡¦ç†æ™‚é–“: æ­£å¸¸å®Œäº†")
                
                # ãƒ—ãƒ­ã‚¯ãƒ©ã‚¹ãƒ†ã‚¹è§£æã®èª¬æ˜
                with st.expander("ğŸ“š ãƒ—ãƒ­ã‚¯ãƒ©ã‚¹ãƒ†ã‚¹è§£æã¨ã¯"):
                    st.write("""
                    **ãƒ—ãƒ­ã‚¯ãƒ©ã‚¹ãƒ†ã‚¹è§£æ**ã¯2ã¤ã®å½¢çŠ¶ã®é¡ä¼¼åº¦ã‚’æ¸¬å®šã™ã‚‹çµ±è¨ˆæ‰‹æ³•ã§ã™ã€‚
                    
                    ğŸ“Œ **ç‰¹å¾´:**
                    - ä½ç½®ã€å›è»¢ã€ã‚¹ã‚±ãƒ¼ãƒ«ã®é•ã„ã‚’å–ã‚Šé™¤ã„ã¦å½¢çŠ¶ã‚’æ¯”è¼ƒ
                    - å€¤ãŒå°ã•ã„ã»ã©å½¢çŠ¶ãŒé¡ä¼¼ã—ã¦ã„ã‚‹
                    - é¡”ã®ç‰¹å¾´ç‚¹ã®é…ç½®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®šé‡çš„ã«æ¯”è¼ƒ
                    
                    ğŸ“Š **ã‚¹ã‚³ã‚¢ã®è§£é‡ˆ:**
                    - 0.00-0.05: éå¸¸ã«é¡ä¼¼
                    - 0.05-0.15: é¡ä¼¼
                    - 0.15-0.30: ã‚„ã‚„é¡ä¼¼
                    - 0.30ä»¥ä¸Š: é¡ä¼¼åº¦ä½
                    """)
        
        else:
            st.warning("ç”»åƒå‡¦ç†ã‚’å®Œäº†ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„:")
            st.write("- ç”»åƒã«é¡”ãŒæ˜ç¢ºã«å†™ã£ã¦ã„ã‚‹ã‹")
            st.write("- ç”»åƒã®è§£åƒåº¦ãŒååˆ†ã‹")
            st.write("- é¡”ãŒæ­£é¢ã‚’å‘ã„ã¦ã„ã‚‹ã‹")
            st.write("- ç…§æ˜æ¡ä»¶ãŒè‰¯å¥½ã‹")

def manual_annotation_mode(uploaded_base, uploaded_comp1, uploaded_comp2, col1, col2, col3):
    if 'manual_points' not in st.session_state:
        st.session_state.manual_points = {'base': [], 'comp1': [], 'comp2': []}
    
    target_image = st.radio("æ³¨é‡ˆå¯¾è±¡ç”»åƒ", ["åŸºæº–ç”»åƒ", "æ¯”è¼ƒç”»åƒ1", "æ¯”è¼ƒç”»åƒ2"])
    
    if uploaded_base and uploaded_comp1 and uploaded_comp2:
        images = {
            'åŸºæº–ç”»åƒ': np.array(Image.open(uploaded_base).convert('RGB')),
            'æ¯”è¼ƒç”»åƒ1': np.array(Image.open(uploaded_comp1).convert('RGB')),
            'æ¯”è¼ƒç”»åƒ2': np.array(Image.open(uploaded_comp2).convert('RGB'))
        }
        
        keys = {'åŸºæº–ç”»åƒ': 'base', 'æ¯”è¼ƒç”»åƒ1': 'comp1', 'æ¯”è¼ƒç”»åƒ2': 'comp2'}
        
        current_key = keys[target_image]
        current_image = images[target_image]
        
        plotted_image = draw_manual_points(current_image, st.session_state.manual_points[current_key])
        
        coords = streamlit_image_coordinates(
            plotted_image,
            key=f"coords_{target_image}",
            width=400
        )
        
        if coords is not None:
            x, y = coords["x"], coords["y"]
            st.session_state.manual_points[current_key].append([x, y])
            st.rerun()
        
        col_button1, col_button2 = st.columns(2)
        with col_button1:
            if st.button("æœ€å¾Œã®ç‚¹ã‚’å‰Šé™¤"):
                if st.session_state.manual_points[current_key]:
                    st.session_state.manual_points[current_key].pop()
                    st.rerun()
        
        with col_button2:
            if st.button("å…¨ç‚¹ã‚’ã‚¯ãƒªã‚¢"):
                st.session_state.manual_points[current_key] = []
                st.rerun()
        
        st.write(f"{target_image}ã®ç‚¹æ•°: {len(st.session_state.manual_points[current_key])}")
        
        points_counts = [len(st.session_state.manual_points[k]) for k in ['base', 'comp1', 'comp2']]
        
        if all(count >= 3 for count in points_counts) and len(set(points_counts)) == 1:
            if st.button("é¡ä¼¼åº¦ã‚’è¨ˆç®—ã™ã‚‹"):
                base_points = np.array(st.session_state.manual_points['base'])
                comp1_points = np.array(st.session_state.manual_points['comp1'])
                comp2_points = np.array(st.session_state.manual_points['comp2'])
                
                similarity1 = calculate_procrustes_similarity(base_points, comp1_points)
                similarity2 = calculate_procrustes_similarity(base_points, comp2_points)
                
                st.subheader("æ‰‹å‹•æ³¨é‡ˆã«ã‚ˆã‚‹é¡ä¼¼åº¦åˆ†æçµæœ")
                col_result1, col_result2 = st.columns(2)
                
                with col_result1:
                    st.metric("åŸºæº– vs æ¯”è¼ƒ1", f"{similarity1:.4f}", help="å€¤ãŒå°ã•ã„ã»ã©é¡ä¼¼")
                
                with col_result2:
                    st.metric("åŸºæº– vs æ¯”è¼ƒ2", f"{similarity2:.4f}", help="å€¤ãŒå°ã•ã„ã»ã©é¡ä¼¼")
                
                if similarity1 < similarity2:
                    st.success("æ¯”è¼ƒç”»åƒ1ã®æ–¹ãŒåŸºæº–ç”»åƒã«ã‚ˆã‚Šé¡ä¼¼ã—ã¦ã„ã¾ã™")
                else:
                    st.success("æ¯”è¼ƒç”»åƒ2ã®æ–¹ãŒåŸºæº–ç”»åƒã«ã‚ˆã‚Šé¡ä¼¼ã—ã¦ã„ã¾ã™")
        
        elif any(count > 0 for count in points_counts):
            st.info(f"å…¨ã¦ã®ç”»åƒã«åŒæ•°ã®ç‚¹ï¼ˆ3ç‚¹ä»¥ä¸Šï¼‰ã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã¦ãã ã•ã„ã€‚ç¾åœ¨: åŸºæº–{points_counts[0]}ç‚¹, æ¯”è¼ƒ1{points_counts[1]}ç‚¹, æ¯”è¼ƒ2{points_counts[2]}ç‚¹")

def draw_manual_points(image, points):
    if not points:
        return image
    
    plotted_image = image.copy()
    for point in points:
        x, y = int(point[0]), int(point[1])
        cv2.circle(plotted_image, (x, y), 3, (255, 0, 0), -1)
    
    return plotted_image

if __name__ == "__main__":
    main()