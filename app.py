import streamlit as st
import numpy as np
import cv2
import mediapipe as mp
from scipy.spatial import procrustes
from streamlit_image_coordinates import streamlit_image_coordinates
from PIL import Image


def preprocess_image_to_square(image, target_size=800):
    """
    ç”»åƒã‚’æŒ‡å®šã‚µã‚¤ã‚ºã®æ­£æ–¹å½¢ã«è‡ªå‹•ãƒªã‚µã‚¤ã‚ºãƒ»ã‚»ãƒ³ã‚¿ãƒ¼ã‚¯ãƒ­ãƒƒãƒ—

    Args:
        image: PIL Image ã¾ãŸã¯ numpy array
        target_size: ç›®æ¨™ã‚µã‚¤ã‚ºï¼ˆæ­£æ–¹å½¢ï¼‰

    Returns:
        PIL Image: å‰å‡¦ç†æ¸ˆã¿ã®æ­£æ–¹å½¢ç”»åƒ
    """
    # numpy arrayã®å ´åˆã¯PIL Imageã«å¤‰æ›
    if isinstance(image, np.ndarray):
        if len(image.shape) == 3:
            # RGBã®å ´åˆ
            pil_image = Image.fromarray(image)
        else:
            # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã®å ´åˆ
            pil_image = Image.fromarray(image, "L")
    else:
        pil_image = image.copy()

    # ç”»åƒã‚’æ¬ ã‘ãªã„ã‚ˆã†ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã§æ­£æ–¹å½¢åŒ–ï¼ˆé¡”æ¤œå‡ºã¯ä½¿ç”¨ã—ãªã„ï¼‰
    pil_image = pad_image_to_square(pil_image)

    # æœ€çµ‚çš„ã«æŒ‡å®šã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚º
    processed_image = pil_image.resize((target_size, target_size), Image.LANCZOS)

    return processed_image


def pad_image_to_square(pil_image):
    """
    ç”»åƒã‚’æ­£æ–¹å½¢ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆç”»åƒã‚’æ¬ ã‘ãªã„ã‚ˆã†ã«é»’ã„å¸¯ã‚’è¿½åŠ ï¼‰

    Args:
        pil_image: PIL Image

    Returns:
        PIL Image: æ­£æ–¹å½¢ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã•ã‚ŒãŸç”»åƒ
    """
    width, height = pil_image.size

    # æ­£æ–¹å½¢ã®ã‚µã‚¤ã‚ºã¯é•·è¾ºã«åˆã‚ã›ã‚‹
    square_size = max(width, height)

    # æ–°ã—ã„æ­£æ–¹å½¢ç”»åƒã‚’ä½œæˆï¼ˆé»’èƒŒæ™¯ï¼‰
    square_image = Image.new("RGB", (square_size, square_size), (0, 0, 0))

    # å…ƒç”»åƒã‚’ä¸­å¤®ã«é…ç½®
    x_offset = (square_size - width) // 2
    y_offset = (square_size - height) // 2

    # å…ƒç”»åƒã‚’æ­£æ–¹å½¢ç”»åƒã®ä¸­å¤®ã«è²¼ã‚Šä»˜ã‘
    square_image.paste(pil_image, (x_offset, y_offset))

    return square_image


@st.cache_resource
def initialize_face_landmarker():
    BaseOptions = mp.tasks.BaseOptions
    FaceLandmarker = mp.tasks.vision.FaceLandmarker
    FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions
    VisionRunningMode = mp.tasks.vision.RunningMode

    options = FaceLandmarkerOptions(
        base_options=BaseOptions(
            model_asset_path="face_landmarker_v2_with_blendshapes.task"
        ),
        running_mode=VisionRunningMode.IMAGE,
    )
    return FaceLandmarker.create_from_options(options)


def extract_landmarks(image, landmarker):
    try:
        # ç”»åƒãŒRGBã®å ´åˆã¯ãã®ã¾ã¾ä½¿ç”¨ã€BGRã®å ´åˆã¯å¤‰æ›
        if len(image.shape) == 3 and image.shape[2] == 3:
            # RGBã¨ä»®å®šã—ã¦å‡¦ç†
            image_rgb = image.copy()
        else:
            st.error(f"ç”»åƒå½¢çŠ¶ãŒäºˆæœŸã—ãªã„å½¢å¼ã§ã™: {image.shape}")
            return None, "ç”»åƒå½¢çŠ¶ã‚¨ãƒ©ãƒ¼"

        # ãƒ‡ãƒ¼ã‚¿å‹ã‚’uint8ã«ç¢ºå®Ÿã«å¤‰æ›
        if image_rgb.dtype != np.uint8:
            image_rgb = (
                (image_rgb * 255).astype(np.uint8)
                if image_rgb.max() <= 1.0
                else image_rgb.astype(np.uint8)
            )

        # ç”»åƒãŒé€£ç¶šé…åˆ—ã§ã‚ã‚‹ã“ã¨ã‚’ä¿è¨¼
        image_rgb = np.ascontiguousarray(image_rgb)

        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image_rgb)
        result = landmarker.detect(mp_image)

        if result.face_landmarks and len(result.face_landmarks) > 0:
            landmarks = result.face_landmarks[0]
            points = np.array(
                [
                    [lm.x * image.shape[1], lm.y * image.shape[0], lm.z]
                    for lm in landmarks
                ]
            )
            return points, None
        else:
            return (
                None,
                f"é¡”ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚æ¤œå‡ºã•ã‚ŒãŸé¡”ã®æ•°: {len(result.face_landmarks) if result.face_landmarks else 0}",
            )

    except Exception as e:
        st.error(f"ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æŠ½å‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None, f"ã‚¨ãƒ©ãƒ¼: {str(e)}"


def calculate_procrustes_similarity(landmarks1, landmarks2):
    mtx1, mtx2, disparity = procrustes(landmarks1, landmarks2)
    return disparity


def calculate_cosine_similarity(landmarks1, landmarks2):
    """
    ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã«ã‚ˆã‚‹é¡”ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯é¡ä¼¼åº¦è¨ˆç®—
    æˆ»ã‚Šå€¤: 0-1ã®ç¯„å›²ã§1ã«è¿‘ã„ã»ã©é¡ä¼¼
    """
    # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’ãƒ•ãƒ©ãƒƒãƒˆåŒ–ã—ã¦1æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›
    vector1 = landmarks1.flatten()
    vector2 = landmarks2.flatten()

    # æ­£è¦åŒ–
    norm1 = np.linalg.norm(vector1)
    norm2 = np.linalg.norm(vector2)

    if norm1 == 0 or norm2 == 0:
        return 0.0

    # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—
    cosine_sim = np.dot(vector1, vector2) / (norm1 * norm2)

    # 0-1ã®ç¯„å›²ã«ã‚¯ãƒªãƒƒãƒ—ï¼ˆæ•°å€¤èª¤å·®å¯¾ç­–ï¼‰
    return max(0.0, min(1.0, cosine_sim))


def calculate_normalized_euclidean_similarity(landmarks1, landmarks2):
    """
    æ­£è¦åŒ–ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã«ã‚ˆã‚‹é¡ä¼¼åº¦è¨ˆç®—
    æˆ»ã‚Šå€¤: 0-1ã®ç¯„å›²ã§1ã«è¿‘ã„ã»ã©é¡ä¼¼
    """
    # å„ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚»ãƒƒãƒˆã‚’æ­£è¦åŒ–ï¼ˆå¹³å‡0ã€æ¨™æº–åå·®1ï¼‰
    normalized1 = (landmarks1 - np.mean(landmarks1, axis=0)) / (
        np.std(landmarks1, axis=0) + 1e-8
    )
    normalized2 = (landmarks2 - np.mean(landmarks2, axis=0)) / (
        np.std(landmarks2, axis=0) + 1e-8
    )

    # ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢è¨ˆç®—
    distance = np.sqrt(np.sum((normalized1 - normalized2) ** 2))

    # è·é›¢ã‚’é¡ä¼¼åº¦ã«å¤‰æ›ï¼ˆã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¢æ•°ä½¿ç”¨ï¼‰
    similarity = 1 / (1 + distance / 10)

    return similarity


def calculate_hausdorff_similarity(landmarks1, landmarks2):
    """
    ä¿®æ­£ãƒã‚¦ã‚¹ãƒ‰ãƒ«ãƒ•è·é›¢ã«ã‚ˆã‚‹é¡ä¼¼åº¦è¨ˆç®—
    æˆ»ã‚Šå€¤: 0-1ã®ç¯„å›²ã§1ã«è¿‘ã„ã»ã©é¡ä¼¼
    """

    def modified_hausdorff_distance(set1, set2):
        # set1ã®å„ç‚¹ã‹ã‚‰set2ã¸ã®æœ€çŸ­è·é›¢ã®å¹³å‡
        distances1 = []
        for point in set1:
            min_dist = min([np.linalg.norm(point - p2) for p2 in set2])
            distances1.append(min_dist)

        # set2ã®å„ç‚¹ã‹ã‚‰set1ã¸ã®æœ€çŸ­è·é›¢ã®å¹³å‡
        distances2 = []
        for point in set2:
            min_dist = min([np.linalg.norm(point - p1) for p1 in set1])
            distances2.append(min_dist)

        # ä¿®æ­£ãƒã‚¦ã‚¹ãƒ‰ãƒ«ãƒ•è·é›¢ï¼ˆå¹³å‡ã®æœ€å¤§å€¤ï¼‰
        return max(np.mean(distances1), np.mean(distances2))

    # 2Dåº§æ¨™ã®ã¿ä½¿ç”¨ï¼ˆzåº§æ¨™ã¯é™¤å¤–ï¼‰
    points1 = landmarks1[:, :2]
    points2 = landmarks2[:, :2]

    # ä¿®æ­£ãƒã‚¦ã‚¹ãƒ‰ãƒ«ãƒ•è·é›¢è¨ˆç®—
    distance = modified_hausdorff_distance(points1, points2)

    # è·é›¢ã‚’é¡ä¼¼åº¦ã«å¤‰æ›
    similarity = 1 / (1 + distance / 50)

    return similarity


def calculate_combined_similarity(landmarks1, landmarks2):
    """
    è¤‡æ•°ã®é¡ä¼¼åº¦æŒ‡æ¨™ã‚’çµ„ã¿åˆã‚ã›ãŸç·åˆè©•ä¾¡
    æˆ»ã‚Šå€¤: 0-1ã®ç¯„å›²ã§1ã«è¿‘ã„ã»ã©é¡ä¼¼
    """
    # å„æŒ‡æ¨™ã‚’è¨ˆç®—
    cosine_sim = calculate_cosine_similarity(landmarks1, landmarks2)
    euclidean_sim = calculate_normalized_euclidean_similarity(landmarks1, landmarks2)
    hausdorff_sim = calculate_hausdorff_similarity(landmarks1, landmarks2)

    # ãƒ—ãƒ­ã‚¯ãƒ©ã‚¹ãƒ†ã‚¹è·é›¢ã‚’é¡ä¼¼åº¦ã«å¤‰æ›
    procrustes_dist = calculate_procrustes_similarity(landmarks1, landmarks2)
    procrustes_sim = 1 / (1 + procrustes_dist * 10)

    # é‡ã¿ä»˜ãå¹³å‡ï¼ˆãƒ—ãƒ­ã‚¯ãƒ©ã‚¹ãƒ†ã‚¹ã¨ã‚³ã‚µã‚¤ãƒ³ã‚’é‡è¦–ï¼‰
    weights = {"cosine": 0.3, "euclidean": 0.2, "hausdorff": 0.2, "procrustes": 0.3}

    combined_similarity = (
        weights["cosine"] * cosine_sim
        + weights["euclidean"] * euclidean_sim
        + weights["hausdorff"] * hausdorff_sim
        + weights["procrustes"] * procrustes_sim
    )

    return combined_similarity


def draw_landmarks_on_image(image, landmarks):
    if landmarks is None:
        return image

    annotated_image = image.copy()
    height, width = image.shape[:2]

    # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®ã‚µã‚¤ã‚ºã‚’ç”»åƒã‚µã‚¤ã‚ºã«å¿œã˜ã¦èª¿æ•´
    point_size = max(1, min(width, height) // 200)

    # MediaPipeã®é¡”ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ¥ç¶šæƒ…å ±ï¼ˆä¸»è¦ãªé¡”ã®è¼ªéƒ­ï¼‰
    connections = [
        # é¡”ã®è¼ªéƒ­ (0-16)
        [(i, i + 1) for i in range(16)],
        # å·¦çœ‰æ¯› (17-21)
        [(i, i + 1) for i in range(17, 21)],
        # å³çœ‰æ¯› (22-26)
        [(i, i + 1) for i in range(22, 26)],
        # é¼»ç­‹ (27-30)
        [(i, i + 1) for i in range(27, 30)],
        # é¼»ã®ä¸‹éƒ¨ (31-35)
        [(i, i + 1) for i in range(31, 35)],
        # å·¦ç›® (36-41)
        [(i, i + 1) for i in range(36, 41)] + [(41, 36)],
        # å³ç›® (42-47)
        [(i, i + 1) for i in range(42, 47)] + [(47, 42)],
        # å¤–å”‡ (48-59)
        [(i, i + 1) for i in range(48, 59)] + [(59, 48)],
        # å†…å”‡ (60-67)
        [(i, i + 1) for i in range(60, 67)] + [(67, 60)],
    ]

    # ç·šã‚’æç”»ï¼ˆMediaPipeã®å…¨478ç‚¹ã§ã¯è¤‡é›‘ã™ãã‚‹ã®ã§ã€ä¸»è¦ãª68ç‚¹ã®ã¿è¡¨ç¤ºï¼‰
    if len(landmarks) >= 68:
        for connection_group in connections:
            for start_idx, end_idx in connection_group:
                if start_idx < len(landmarks) and end_idx < len(landmarks):
                    start_point = (
                        int(landmarks[start_idx][0]),
                        int(landmarks[start_idx][1]),
                    )
                    end_point = (int(landmarks[end_idx][0]), int(landmarks[end_idx][1]))
                    cv2.line(annotated_image, start_point, end_point, (0, 255, 255), 1)

    # å…¨ãƒã‚¤ãƒ³ãƒˆã‚’æç”»
    for i, point in enumerate(landmarks):
        x, y = int(point[0]), int(point[1])

        # é‡è¦ãªãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã¯å¤§ããè¡¨ç¤º
        if i < 68:  # ä¸»è¦ãª68ç‚¹
            if i in [36, 39, 42, 45]:  # ç›®ã®è§’
                cv2.circle(
                    annotated_image, (x, y), point_size + 1, (255, 0, 0), -1
                )  # é’
            elif i in [48, 54]:  # å£ã®è§’
                cv2.circle(
                    annotated_image, (x, y), point_size + 1, (0, 0, 255), -1
                )  # èµ¤
            elif i in [30]:  # é¼»ã®å…ˆç«¯
                cv2.circle(
                    annotated_image, (x, y), point_size + 1, (255, 255, 0), -1
                )  # ã‚·ã‚¢ãƒ³
            else:
                cv2.circle(annotated_image, (x, y), point_size, (0, 255, 0), -1)  # ç·‘
        else:  # ãã®ä»–ã®è©³ç´°ãƒã‚¤ãƒ³ãƒˆ
            cv2.circle(
                annotated_image, (x, y), max(1, point_size // 2), (0, 255, 0), -1
            )  # å°ã•ã„ç·‘

    # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ•°ã‚’ç”»åƒã«è¡¨ç¤º
    cv2.putText(
        annotated_image,
        f"Points: {len(landmarks)}",
        (10, 30),
        cv2.FONT_HERSHEY_SIMPLEX,
        0.7,
        (255, 255, 255),
        2,
    )

    return annotated_image


def main():
    st.set_page_config(
        page_title="é¡”å½¢çŠ¶é¡ä¼¼åº¦åˆ†æã‚¢ãƒ—ãƒª",
        layout="wide",
        page_icon="ğŸ­",
        initial_sidebar_state="collapsed",
    )

    # ã‚«ã‚¹ã‚¿ãƒ CSS
    st.markdown(
        """
    <style>
    .main {
        padding-top: 2rem;
    }
    .app-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem 0;
        border-radius: 15px;
        margin-bottom: 2rem;
        text-align: center;
        box-shadow: 0 10px 30px rgba(0,0,0,0.1);
    }
    .app-title {
        color: white;
        font-size: 3rem;
        font-weight: 700;
        margin: 0;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
    }
    .app-subtitle {
        color: rgba(255,255,255,0.9);
        font-size: 1.2rem;
        margin-top: 0.5rem;
        font-weight: 300;
    }
    .result-section {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        padding: 2rem;
        border-radius: 15px;
        margin: 2rem 0;
    }
    .winner-card {
        background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 15px;
        text-align: center;
        box-shadow: 0 8px 25px rgba(17,153,142,0.3);
        margin: 1rem 0;
    }
    .progress-indicator {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        height: 4px;
        border-radius: 2px;
        margin: 1rem 0;
    }
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 10px;
        padding: 0.75rem 1.5rem;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(102,126,234,0.3);
    }
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(102,126,234,0.4);
    }
    .feature-badge {
        background: linear-gradient(135deg, #ffecd2 0%, #fcb69f 100%);
        padding: 0.5rem 1rem;
        border-radius: 20px;
        display: inline-block;
        font-size: 0.9rem;
        font-weight: 600;
        color: #8b4513;
        margin: 0.2rem;
    }
    .stHorizontalBlock > div:nth-child(1),
    .stHorizontalBlock > div:nth-child(2) {
        background: linear-gradient(135deg, #abd5ff88 0%, #a2dafccc 100%);
        padding: 1rem;
        border-radius: 10px;
    }
    .stHorizontalBlock > div:nth-child(3) {
        background: linear-gradient(135deg, #ffd5e688 0%, #ffdaebcc 100%);
        padding: 1rem;
        border-radius: 10px;
    }

    </style>
    """,
        unsafe_allow_html=True,
    )

    # ã‚¢ãƒ—ãƒªãƒ˜ãƒƒãƒ€ãƒ¼
    st.markdown(
        """
<h1 class="app-title"> é¡”å½¢çŠ¶é¡ä¼¼åº¦åˆ†æã‚¢ãƒ—ãƒª</h1>
    """,
        unsafe_allow_html=True,
    )

    # ãƒ¢ãƒ¼ãƒ‰é¸æŠã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.markdown("###  åˆ†æãƒ¢ãƒ¼ãƒ‰é¸æŠ")
    mode = st.selectbox(
        "åˆ†æãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ",
        ["AIè‡ªå‹•è§£æãƒ¢ãƒ¼ãƒ‰", "æ‰‹å‹•æ³¨é‡ˆãƒ¢ãƒ¼ãƒ‰"],
        label_visibility="collapsed",
    )

    # ãƒ¢ãƒ¼ãƒ‰ã®èª¬æ˜
    if "è‡ªå‹•" in mode:
        st.info(
            " **AIè‡ªå‹•è§£æãƒ¢ãƒ¼ãƒ‰**: MediaPipeã‚’ä½¿ç”¨ã—ã¦é¡”ã®ç‰¹å¾´ç‚¹ã‚’è‡ªå‹•æ¤œå‡ºã—ã€é«˜ç²¾åº¦ãªé¡ä¼¼åº¦åˆ†æã‚’å®Ÿè¡Œã—ã¾ã™ã€‚"
        )
    else:
        st.info(
            " **æ‰‹å‹•æ³¨é‡ˆãƒ¢ãƒ¼ãƒ‰**: æ‰‹å‹•ã§ç‰¹å¾´ç‚¹ã‚’æŒ‡å®šã—ã¦ã€ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã•ã‚ŒãŸé¡ä¼¼åº¦åˆ†æã‚’å®Ÿè¡Œã—ã¾ã™ã€‚"
        )

    # é¡ä¼¼åº¦æŒ‡æ¨™é¸æŠ
    st.markdown("###  é¡ä¼¼åº¦æŒ‡æ¨™é¸æŠ")
    similarity_metric = st.selectbox(
        "é¡ä¼¼åº¦æŒ‡æ¨™ã‚’é¸æŠ",
        [
            "ç·åˆè©•ä¾¡",
            "ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦",
            "æ­£è¦åŒ–ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢",
            "ä¿®æ­£ãƒã‚¦ã‚¹ãƒ‰ãƒ«ãƒ•è·é›¢",
            "ãƒ—ãƒ­ã‚¯ãƒ©ã‚¹ãƒ†ã‚¹è§£æ",
        ],
        label_visibility="collapsed",
        help="ã©ã®é¡ä¼¼åº¦æŒ‡æ¨™ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã‚’é¸æŠã—ã¦ãã ã•ã„",
    )

    # æŒ‡æ¨™ã®èª¬æ˜
    if "ç·åˆè©•ä¾¡" in similarity_metric:
        st.success(
            " **ç·åˆè©•ä¾¡**: è¤‡æ•°ã®æŒ‡æ¨™ã‚’çµ„ã¿åˆã‚ã›ãŸæœ€ã‚‚ä¿¡é ¼æ€§ã®é«˜ã„è©•ä¾¡æ–¹æ³•ã§ã™"
        )
    elif "ã‚³ã‚µã‚¤ãƒ³" in similarity_metric:
        st.info(" **ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦**: 1ã«è¿‘ã„ã»ã©é¡ä¼¼ã€‚è§’åº¦ã®é¡ä¼¼æ€§ã‚’æ¸¬å®šã—ã¾ã™")
    elif "ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰" in similarity_metric:
        st.info(
            " **æ­£è¦åŒ–ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢**: 1ã«è¿‘ã„ã»ã©é¡ä¼¼ã€‚æ­£è¦åŒ–ã•ã‚ŒãŸè·é›¢ã‚’æ¸¬å®šã—ã¾ã™"
        )
    elif "ãƒã‚¦ã‚¹ãƒ‰ãƒ«ãƒ•" in similarity_metric:
        st.info(
            " **ä¿®æ­£ãƒã‚¦ã‚¹ãƒ‰ãƒ«ãƒ•è·é›¢**: 1ã«è¿‘ã„ã»ã©é¡ä¼¼ã€‚å½¢çŠ¶ã®é•ã„ã‚’è©³ç´°ã«æ¸¬å®šã—ã¾ã™"
        )
    else:
        st.warning(" **ãƒ—ãƒ­ã‚¯ãƒ©ã‚¹ãƒ†ã‚¹è§£æ**: 0ã«è¿‘ã„ã»ã©é¡ä¼¼ã€‚")

    # ç”»åƒå‰å‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    st.markdown("###  ç”»åƒå‰å‡¦ç†è¨­å®š")
    image_preprocessing = st.checkbox(
        "è‡ªå‹•ç”»åƒå‰å‡¦ç†ã‚’æœ‰åŠ¹ã«ã™ã‚‹",
        value=True,
        help="ç”»åƒã‚’800x800ã®æ­£æ–¹å½¢ã«è‡ªå‹•ãƒªã‚µã‚¤ã‚ºã—ã€ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç‚¹ã®å¤§ãã•ã‚’çµ±ä¸€ã—ã¾ã™",
    )

    if image_preprocessing:
        st.success(" **è‡ªå‹•å‰å‡¦ç†ON**: ç”»åƒä¿è­·ãƒ‘ãƒ‡ã‚£ãƒ³ã‚° + 800x800ãƒªã‚µã‚¤ã‚º")
        with st.expander("å‰å‡¦ç†ã®è©³ç´°"):
            st.markdown(
                """
            **å‰å‡¦ç†å†…å®¹:**
            -  **ç”»åƒä¿è­·ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°**: å…ƒç”»åƒã‚’å›²ã‚€ã‚ˆã†ã«é»’ã„å¸¯ã‚’è¿½åŠ 
            -  **æ­£æ–¹å½¢åŒ–**: ç¸¦é•·ãƒ»æ¨ªé•·ã©ã¡ã‚‰ã‚‚é©åˆ‡ã«å‡¦ç†
            -  **800x800ãƒªã‚µã‚¤ã‚º**: é«˜å“è³ªãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆLANCZOSï¼‰
            -  **ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³çµ±ä¸€**: ç‚¹ã®å¤§ãã•ã¨ä½ç½®ç²¾åº¦ã‚’å‘ä¸Š
            
            **ãƒ¡ãƒªãƒƒãƒˆ:**
            - ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç‚¹ã®å¤§ãã•ãŒçµ±ä¸€ã•ã‚Œã‚‹
            - ç”»è³ªã«ã‚ˆã‚‹å½±éŸ¿ã‚’è»½æ¸›
            - ç”»åƒãŒæ¬ ã‘ã‚‹ã“ã¨ãªãå…¨ä½“ãŒä¿æŒã•ã‚Œã‚‹
            - å®‰å…¨ã§ç¢ºå®Ÿãªå‰å‡¦ç†ï¼ˆé¡”æ¤œå‡ºã‚¨ãƒ©ãƒ¼ãªã—ï¼‰
            """
            )
    else:
        st.info(" **è‡ªå‹•å‰å‡¦ç†OFF**: å…ƒç”»åƒã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼ˆç”»è³ªã«ã‚ˆã‚‹å·®ç•°ã‚ã‚Šï¼‰")

    st.markdown("</div>", unsafe_allow_html=True)

    col1, col2, col3 = st.columns(3, gap="large")

    with col1:
        st.markdown("###  åŸºæº–ç”»åƒ (äººç‰©A)")
        st.markdown("**ãƒ¡ã‚¤ãƒ³å‚ç…§ã¨ã—ã¦ä½¿ç”¨ã•ã‚Œã‚‹ç”»åƒ**")
        uploaded_base = st.file_uploader(
            "åŸºæº–ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=["jpg", "jpeg", "png"],
            key="base",
            help="æ¯”è¼ƒã®åŸºæº–ã¨ãªã‚‹äººç‰©Aã®ç”»åƒã‚’é¸æŠã—ã¦ãã ã•ã„",
        )
        if uploaded_base:
            preview_img = Image.open(uploaded_base)
            st.image(
                preview_img, caption=" ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†", use_container_width=True
            )
        st.markdown("</div>", unsafe_allow_html=True)

    with col2:
        st.markdown("###  æ¯”è¼ƒç”»åƒ1 (äººç‰©A)")
        st.markdown("**åŒä¸€äººç‰©ã®åˆ¥ã®å†™çœŸ**")
        uploaded_comp1 = st.file_uploader(
            "æ¯”è¼ƒç”»åƒ1(äººç‰©A)ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=["jpg", "jpeg", "png"],
            key="comp1",
            help="äººç‰©Aã®åˆ¥è§’åº¦ãƒ»åˆ¥è¡¨æƒ…ã®ç”»åƒã‚’é¸æŠã—ã¦ãã ã•ã„",
        )
        if uploaded_comp1:
            preview_img = Image.open(uploaded_comp1)
            st.image(
                preview_img, caption=" ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†", use_container_width=True
            )
        st.markdown("</div>", unsafe_allow_html=True)

    with col3:
        st.markdown("###  æ¯”è¼ƒç”»åƒ2 (äººç‰©B)")
        st.markdown("**é¡ä¼¼åº¦ã‚’æ¤œè¨¼ã—ãŸã„åˆ¥äººç‰©**")

        input_method = st.radio(
            "å…¥åŠ›æ–¹æ³•ã‚’é¸æŠ",
            ["ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ğŸ“¸ ã‚«ãƒ¡ãƒ©ã‚­ãƒ£ãƒ—ãƒãƒ£"],
            key="input_method",
            horizontal=True,
        )

        uploaded_comp2 = None
        camera_image = None

        if "ãƒ•ã‚¡ã‚¤ãƒ«" in input_method:
            uploaded_comp2 = st.file_uploader(
                "æ¯”è¼ƒç”»åƒ2(äººç‰©B)ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
                type=["jpg", "jpeg", "png"],
                key="comp2",
                help="äººç‰©Bã®ç”»åƒã‚’é¸æŠã—ã¦ãã ã•ã„",
            )
            if uploaded_comp2:
                preview_img = Image.open(uploaded_comp2)
                st.image(
                    preview_img, caption=" ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†", use_container_width=True
                )
        else:
            st.markdown("####  ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ’®å½±")
            st.markdown(
                """
            <strong> æ’®å½±ã®ã‚³ãƒ„:</strong><br>
                æ˜ã‚‹ã„å ´æ‰€ã§æ’®å½±<br>
                é¡”ãŒæ­£é¢ã‚’å‘ã<br>
                é©åº¦ãªè·é›¢ã‚’ä¿ã¤
            """,
                unsafe_allow_html=True,
            )

            camera_image = st.camera_input(" å†™çœŸã‚’æ’®å½±", key="camera")

            if camera_image is not None:
                uploaded_comp2 = camera_image
                st.success(" æ’®å½±å®Œäº†ï¼")
                preview_image = Image.open(camera_image)
                st.image(preview_image, caption=" æ’®å½±ç”»åƒ", use_container_width=True)

        st.markdown("</div>", unsafe_allow_html=True)

    if "è‡ªå‹•" in mode:
        auto_analysis_mode(
            uploaded_base,
            uploaded_comp1,
            uploaded_comp2,
            col1,
            col2,
            col3,
            similarity_metric,
            image_preprocessing,
        )
    else:
        manual_annotation_mode(
            uploaded_base,
            uploaded_comp1,
            uploaded_comp2,
            col1,
            col2,
            col3,
            similarity_metric,
            image_preprocessing,
        )


def auto_analysis_mode(
    uploaded_base,
    uploaded_comp1,
    uploaded_comp2,
    col1,
    col2,
    col3,
    similarity_metric,
    image_preprocessing,
):
    if uploaded_base and uploaded_comp1 and uploaded_comp2:
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã¨å‡¦ç†çŠ¶æ³
        progress_bar = st.progress(0)
        status_text = st.empty()

        status_text.text(" AIè§£æã‚¨ãƒ³ã‚¸ãƒ³ã‚’åˆæœŸåŒ–ä¸­...")
        progress_bar.progress(10)
        landmarker = initialize_face_landmarker()

        if image_preprocessing:
            status_text.text(" ç”»åƒã‚’å‰å‡¦ç†ä¸­ï¼ˆ800x800ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°å‡¦ç†ï¼‰...")
            progress_bar.progress(30)

            # ç”»åƒã‚’800x800ã«è‡ªå‹•å‰å‡¦ç†ï¼ˆãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã§ç”»åƒä¿è­·ï¼‰
            base_pil = preprocess_image_to_square(
                Image.open(uploaded_base).convert("RGB")
            )
            comp1_pil = preprocess_image_to_square(
                Image.open(uploaded_comp1).convert("RGB")
            )
            comp2_pil = preprocess_image_to_square(
                Image.open(uploaded_comp2).convert("RGB")
            )

            # PIL Imageã‚’NumPy arrayã«å¤‰æ›
            base_image = np.array(base_pil)
            comp1_image = np.array(comp1_pil)
            comp2_image = np.array(comp2_pil)
        else:
            status_text.text(" ç”»åƒã‚’èª­ã¿è¾¼ã¿ä¸­...")
            progress_bar.progress(30)

            # å‰å‡¦ç†ãªã—ã§å…ƒç”»åƒã‚’ãã®ã¾ã¾ä½¿ç”¨
            base_image = np.array(Image.open(uploaded_base).convert("RGB"))
            comp1_image = np.array(Image.open(uploaded_comp1).convert("RGB"))
            comp2_image = np.array(Image.open(uploaded_comp2).convert("RGB"))

        # å‡¦ç†çµæœã‚»ã‚¯ã‚·ãƒ§ãƒ³
        status_text.text(" åŸºæº–ç”»åƒ(äººç‰©A)ã‚’è§£æä¸­...")
        progress_bar.progress(50)
        base_landmarks, base_error = extract_landmarks(base_image, landmarker)

        status_text.text(" æ¯”è¼ƒç”»åƒ1(äººç‰©A)ã‚’è§£æä¸­...")
        progress_bar.progress(70)
        comp1_landmarks, comp1_error = extract_landmarks(comp1_image, landmarker)

        status_text.text(" æ¯”è¼ƒç”»åƒ2(äººç‰©B)ã‚’è§£æä¸­...")
        progress_bar.progress(90)
        comp2_landmarks, comp2_error = extract_landmarks(comp2_image, landmarker)

        status_text.text(" è§£æå®Œäº†ï¼")
        progress_bar.progress(100)

        # ã‚¨ãƒ©ãƒ¼è¡¨ç¤ºï¼ˆæ”¹è‰¯ç‰ˆï¼‰
        errors = []
        if base_error:
            errors.append(f" åŸºæº–ç”»åƒ(äººç‰©A): {base_error}")
        if comp1_error:
            errors.append(f" æ¯”è¼ƒç”»åƒ1(äººç‰©A): {comp1_error}")
        if comp2_error:
            errors.append(f" æ¯”è¼ƒç”»åƒ2(äººç‰©B): {comp2_error}")

        if errors:
            st.markdown("###  æ¤œå‡ºã‚¨ãƒ©ãƒ¼")
            for error in errors:
                st.error(error)
            st.markdown(
                """
            <div style="background: #fff3cd; padding: 1rem; border-radius: 10px; margin: 1rem 0; color: #31333F;">
                <strong> æ”¹å–„ã®ãƒ’ãƒ³ãƒˆ:</strong><br>
                â€¢ é¡”ãŒç”»åƒã®ä¸­å¤®ã«æ˜ç¢ºã«å†™ã£ã¦ã„ã‚‹ã‹ç¢ºèª<br>
                â€¢ ååˆ†ãªæ˜ã‚‹ã•ãŒã‚ã‚‹ã‹ç¢ºèª<br>
                â€¢ é¡”ãŒæ­£é¢ã¾ãŸã¯æ–œã‚45åº¦ä»¥å†…ã‚’å‘ã„ã¦ã„ã‚‹ã‹ç¢ºèª<br>
                â€¢ ç”»åƒè§£åƒåº¦ãŒ300x300ãƒ”ã‚¯ã‚»ãƒ«ä»¥ä¸Šã‚ã‚‹ã‹ç¢ºèª
            </div>
            """,
                unsafe_allow_html=True,
            )

        if (
            base_landmarks is not None
            and comp1_landmarks is not None
            and comp2_landmarks is not None
        ):

            # ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ä»˜ãç”»åƒã‚’ç”Ÿæˆ
            base_annotated = draw_landmarks_on_image(base_image, base_landmarks)
            comp1_annotated = draw_landmarks_on_image(comp1_image, comp1_landmarks)
            comp2_annotated = draw_landmarks_on_image(comp2_image, comp2_landmarks)

            # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ¤œå‡ºçµæœè¡¨ç¤º
            # é¡ä¼¼åº¦è¨ˆç®—ï¼ˆé¸æŠã•ã‚ŒãŸæŒ‡æ¨™ã«å¿œã˜ã¦ï¼‰
            def get_similarity_function(metric):
                if "ç·åˆè©•ä¾¡" in metric:
                    return calculate_combined_similarity
                elif "ã‚³ã‚µã‚¤ãƒ³" in metric:
                    return calculate_cosine_similarity
                elif "ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰" in metric:
                    return calculate_normalized_euclidean_similarity
                elif "ãƒã‚¦ã‚¹ãƒ‰ãƒ«ãƒ•" in metric:
                    return calculate_hausdorff_similarity
                else:  # ãƒ—ãƒ­ã‚¯ãƒ©ã‚¹ãƒ†ã‚¹
                    return calculate_procrustes_similarity

            similarity_func = get_similarity_function(similarity_metric)
            similarity1 = similarity_func(base_landmarks, comp1_landmarks)
            similarity2 = similarity_func(base_landmarks, comp2_landmarks)

            # çµæœè¡¨ç¤ºã‚»ã‚¯ã‚·ãƒ§ãƒ³
            st.markdown("---")
            st.markdown("###  é¡ä¼¼åº¦åˆ†æçµæœ")

            difference = abs(similarity1 - similarity2)

            # æŒ‡æ¨™ã«å¿œã˜ã¦å‹è€…åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ã‚’å¤‰æ›´
            is_procrustes = "ãƒ—ãƒ­ã‚¯ãƒ©ã‚¹ãƒ†ã‚¹" in similarity_metric

            # å‹è€…ã®ç™ºè¡¨ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
            if (is_procrustes and similarity1 < similarity2) or (
                not is_procrustes and similarity1 > similarity2
            ):
                winner = "æ¯”è¼ƒç”»åƒ1(äººç‰©A)"
                winner_score = similarity1
                st.markdown(
                    f"""
                <div class="winner-card">
                    <h3> åˆ†æçµæœ</h3>
                    <h2> {winner}</h2>
                    <p>ãŒåŸºæº–ç”»åƒã«ã‚ˆã‚Šé¡ä¼¼ã—ã¦ã„ã¾ã™</p>
                    <p><strong>ã‚¹ã‚³ã‚¢å·®: {difference:.4f}</strong></p>
                </div>
                """,
                    unsafe_allow_html=True,
                )
            else:
                winner = "æ¯”è¼ƒç”»åƒ2(äººç‰©B)"
                winner_score = similarity2
                st.markdown(
                    f"""
                <div class="winner-card">
                    <h3> åˆ†æçµæœ</h3>
                    <h2> {winner}</h2>
                    <p>ãŒåŸºæº–ç”»åƒã«ã‚ˆã‚Šé¡ä¼¼ã—ã¦ã„ã¾ã™</p>
                    <p><strong>ã‚¹ã‚³ã‚¢å·®: {difference:.4f}</strong></p>
                </div>
                """,
                    unsafe_allow_html=True,
                )

            # è©³ç´°æ¯”è¼ƒè¡¨ç¤º
            detail_col1, detail_col2, detail_col3, detail_col4 = st.columns(
                4, gap="medium"
            )

            with detail_col1:
                st.markdown("####  åŸºæº–ç”»åƒ")
                st.image(base_annotated, caption="åŸºæº–", use_container_width=True)
                st.markdown("</div>", unsafe_allow_html=True)

            with detail_col2:
                st.markdown("####  æ¯”è¼ƒç”»åƒ1(äººç‰©A)")
                st.image(
                    comp1_annotated,
                    caption=f"é¡ä¼¼åº¦: {similarity1:.4f}",
                    use_container_width=True,
                )
                if winner == "æ¯”è¼ƒç”»åƒ1(äººç‰©A)":
                    st.success(" ã‚ˆã‚Šé¡ä¼¼")
                else:
                    st.info(" é¡ä¼¼åº¦ä½")

                # æŒ‡æ¨™ã«å¿œã˜ã¦ãƒ˜ãƒ«ãƒ—ãƒ†ã‚­ã‚¹ãƒˆã‚’å¤‰æ›´
                help_text = f"{similarity_metric}ï¼ˆå€¤ãŒ{'å°ã•ã„' if is_procrustes else 'å¤§ãã„'}ã»ã©é¡ä¼¼ï¼‰"
                st.metric(
                    label=" åŸºæº– vs æ¯”è¼ƒ1",
                    value=f"{similarity1:.4f}",
                    help=help_text,
                )
                st.markdown("</div>", unsafe_allow_html=True)

            with detail_col3:
                st.markdown("####  æ¯”è¼ƒç”»åƒ2(äººç‰©B)")
                st.image(
                    comp2_annotated,
                    caption=f"é¡ä¼¼åº¦: {similarity2:.4f}",
                    use_container_width=True,
                )
                if winner == "æ¯”è¼ƒç”»åƒ2(äººç‰©B)":
                    st.success(" ã‚ˆã‚Šé¡ä¼¼")
                else:
                    st.info(" é¡ä¼¼åº¦ä½")
                st.metric(
                    label=" åŸºæº– vs æ¯”è¼ƒ2",
                    value=f"{similarity2:.4f}",
                    help=help_text,
                )
                st.markdown("</div>", unsafe_allow_html=True)

            with detail_col4:
                st.markdown("####  åˆ†æã‚µãƒãƒªãƒ¼")
                st.markdown(f"æœ€é¡ä¼¼:{winner}")
                st.markdown(f"ã‚¹ã‚³ã‚¢:{winner_score:.4f}")
                st.markdown(f"æ¤œå‡ºç‚¹æ•°:{len(base_landmarks)}ç‚¹")
                st.markdown("å‡¦ç†:æ­£å¸¸å®Œäº†")
                st.markdown(f"é¡ä¼¼åº¦å·®:{abs(similarity1 - similarity2):.4f}")

                # é¸æŠã•ã‚ŒãŸè§£ææ‰‹æ³•ã®èª¬æ˜
                with st.expander(" è§£ææ‰‹æ³•ã«ã¤ã„ã¦"):
                    if "ç·åˆè©•ä¾¡" in similarity_metric:
                        st.markdown(
                            """
                        **ç·åˆè©•ä¾¡**

                         **åŸç†:**
                        - ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã€æ­£è¦åŒ–ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã€ä¿®æ­£ãƒã‚¦ã‚¹ãƒ‰ãƒ«ãƒ•è·é›¢ã€ãƒ—ãƒ­ã‚¯ãƒ©ã‚¹ãƒ†ã‚¹è§£æã‚’çµ„ã¿åˆã‚ã›
                        - å„æ‰‹æ³•ã®é•·æ‰€ã‚’æ´»ã‹ã—ãŸç·åˆçš„ãªåˆ¤å®š
                        - æœ€ã‚‚ä¿¡é ¼æ€§ã®é«˜ã„è©•ä¾¡æ–¹æ³•
                        
                         **ã‚¹ã‚³ã‚¢è§£é‡ˆ:**
                        - `0.80-1.00`:  éå¸¸ã«é¡ä¼¼
                        - `0.60-0.80`:  é¡ä¼¼
                        - `0.40-0.60`:  ã‚„ã‚„é¡ä¼¼
                        - `0.40æœªæº€`:  é¡ä¼¼åº¦ä½
                        """
                        )
                    elif "ã‚³ã‚µã‚¤ãƒ³" in similarity_metric:
                        st.markdown(
                            """
                        **ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦**

                         **åŸç†:**
                        - ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ãƒ™ã‚¯ãƒˆãƒ«é–“ã®è§’åº¦ã‚’æ¸¬å®š
                        - ã‚¹ã‚±ãƒ¼ãƒ«ã«ä¾å­˜ã—ãªã„é¡ä¼¼æ€§è©•ä¾¡
                        - å½¢çŠ¶ã®ç›¸å¯¾çš„ãªé–¢ä¿‚ã‚’é‡è¦–
                        
                         **ã‚¹ã‚³ã‚¢è§£é‡ˆ:**
                        - `0.90-1.00`:  éå¸¸ã«é¡ä¼¼
                        - `0.70-0.90`:  é¡ä¼¼
                        - `0.50-0.70`:  ã‚„ã‚„é¡ä¼¼
                        - `0.50æœªæº€`:  é¡ä¼¼åº¦ä½
                        """
                        )
                    elif "ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰" in similarity_metric:
                        st.markdown(
                            """
                        **æ­£è¦åŒ–ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢**

                         **åŸç†:**
                        - æ­£è¦åŒ–ã•ã‚ŒãŸåº§æ¨™é–“ã®ç›´ç·šè·é›¢ã‚’æ¸¬å®š
                        - ã‚¹ã‚±ãƒ¼ãƒ«ã¨ä½ç½®ã®å½±éŸ¿ã‚’æ’é™¤
                        - çµ¶å¯¾çš„ãªä½ç½®é–¢ä¿‚ã‚’é‡è¦–
                        
                         **ã‚¹ã‚³ã‚¢è§£é‡ˆ:**
                        - `0.80-1.00`:  éå¸¸ã«é¡ä¼¼
                        - `0.60-0.80`:  é¡ä¼¼
                        - `0.40-0.60`:  ã‚„ã‚„é¡ä¼¼
                        - `0.40æœªæº€`:  é¡ä¼¼åº¦ä½
                        """
                        )
                    elif "ãƒã‚¦ã‚¹ãƒ‰ãƒ«ãƒ•" in similarity_metric:
                        st.markdown(
                            """
                        **ä¿®æ­£ãƒã‚¦ã‚¹ãƒ‰ãƒ«ãƒ•è·é›¢**

                         **åŸç†:**
                        - ç‚¹é›†åˆé–“ã®æœ€å¤§æœ€å°è·é›¢ã‚’æ¸¬å®š
                        - å½¢çŠ¶ã®ç´°ã‹ãªé•ã„ã‚’æ¤œå‡º
                        - éƒ¨åˆ†çš„ãªé¡ä¼¼æ€§ã‚‚è€ƒæ…®
                        
                         **ã‚¹ã‚³ã‚¢è§£é‡ˆ:**
                        - `0.80-1.00`:  éå¸¸ã«é¡ä¼¼
                        - `0.60-0.80`:  é¡ä¼¼
                        - `0.40-0.60`:  ã‚„ã‚„é¡ä¼¼
                        - `0.40æœªæº€`:  é¡ä¼¼åº¦ä½
                        """
                        )
                    else:  # ãƒ—ãƒ­ã‚¯ãƒ©ã‚¹ãƒ†ã‚¹
                        st.markdown(
                            """
                        **ãƒ—ãƒ­ã‚¯ãƒ©ã‚¹ãƒ†ã‚¹è§£æ**

                         **åŸç†:**
                        - 2ã¤ã®å½¢çŠ¶ã®ä½ç½®ãƒ»å›è»¢ãƒ»ã‚¹ã‚±ãƒ¼ãƒ«ã‚’æ­£è¦åŒ–
                        - ç´”ç²‹ãªå½¢çŠ¶ã®é•ã„ã®ã¿ã‚’æ¸¬å®š
                        - çµ±è¨ˆçš„ã«ä¿¡é ¼æ€§ã®é«˜ã„æ‰‹æ³•
                        
                         **ã‚¹ã‚³ã‚¢è§£é‡ˆ:**
                        - `0.00-0.05`:  éå¸¸ã«é¡ä¼¼
                        - `0.05-0.15`:  é¡ä¼¼
                        - `0.15-0.30`:  ã‚„ã‚„é¡ä¼¼
                        - `0.30ä»¥ä¸Š`:  é¡ä¼¼åº¦ä½
                        """
                        )
                st.markdown("</div>", unsafe_allow_html=True)

        st.markdown("</div>", unsafe_allow_html=True)

        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ã‚¯ãƒªã‚¢
        progress_bar.empty()
        status_text.empty()

    else:
        st.markdown(
            """
        <div style="background: linear-gradient(135deg, #ffeaa7 0%, #fab1a0 100%); color: #31333F;
                    padding: 2rem; border-radius: 15px; text-align: center; margin: 2rem 0;">
            <h3> ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦é–‹å§‹</h3>
            <p>3ã¤ã®ç”»åƒã‚’ã™ã¹ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€AIè§£æãŒè‡ªå‹•ã§é–‹å§‹ã•ã‚Œã¾ã™</p>
        </div>
        """,
            unsafe_allow_html=True,
        )


def manual_annotation_mode(
    uploaded_base,
    uploaded_comp1,
    uploaded_comp2,
    col1,
    col2,
    col3,
    similarity_metric,
    image_preprocessing,
):
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if "manual_points" not in st.session_state:
        st.session_state.manual_points = {"base": [], "comp1": [], "comp2": []}
    if "current_point_index" not in st.session_state:
        st.session_state.current_point_index = 0
    if "current_image_step" not in st.session_state:
        st.session_state.current_image_step = 0  # 0: base, 1: comp1, 2: comp2

    if uploaded_base and uploaded_comp1 and uploaded_comp2:
        if image_preprocessing:
            # ç”»åƒã‚’800x800ã«è‡ªå‹•å‰å‡¦ç†ï¼ˆãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã§ç”»åƒä¿è­·ï¼‰
            base_pil = preprocess_image_to_square(
                Image.open(uploaded_base).convert("RGB")
            )
            comp1_pil = preprocess_image_to_square(
                Image.open(uploaded_comp1).convert("RGB")
            )
            comp2_pil = preprocess_image_to_square(
                Image.open(uploaded_comp2).convert("RGB")
            )

            images = {
                "base": np.array(base_pil),
                "comp1": np.array(comp1_pil),
                "comp2": np.array(comp2_pil),
            }
        else:
            # å‰å‡¦ç†ãªã—ã§å…ƒç”»åƒã‚’ãã®ã¾ã¾ä½¿ç”¨
            images = {
                "base": np.array(Image.open(uploaded_base).convert("RGB")),
                "comp1": np.array(Image.open(uploaded_comp1).convert("RGB")),
                "comp2": np.array(Image.open(uploaded_comp2).convert("RGB")),
            }

        image_names = [
            " åŸºæº–ç”»åƒ(äººç‰©A)",
            " æ¯”è¼ƒç”»åƒ1(äººç‰©A)",
            " æ¯”è¼ƒç”»åƒ2(äººç‰©B)",
        ]
        image_keys = ["base", "comp1", "comp2"]

        # ç¾åœ¨ã®ãƒã‚¤ãƒ³ãƒˆæ•°ã‚’ç¢ºèª
        total_points = len(st.session_state.manual_points["base"])

        # æ‰‹å‹•ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ˜ãƒƒãƒ€ãƒ¼
        st.markdown('<div class="result-section">', unsafe_allow_html=True)
        st.markdown("###  æ‰‹å‹•ç‰¹å¾´ç‚¹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³")

        # å‰å‡¦ç†çŠ¶æ³ã®è¡¨ç¤º
        if image_preprocessing:
            st.success(
                " ç”»åƒå‰å‡¦ç†æ¸ˆã¿: 800x800ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°å‡¦ç†ï¼ˆã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç‚¹ã‚µã‚¤ã‚ºçµ±ä¸€ï¼‰"
            )
        else:
            st.info(" å…ƒç”»åƒã‚’ä½¿ç”¨ä¸­ï¼ˆç”»è³ªã«ã‚ˆã‚‹ç‚¹ã‚µã‚¤ã‚ºã®å·®ç•°ã‚ã‚Šï¼‰")

        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤º
        current_step = st.session_state.current_image_step
        current_name = image_names[current_step]

        st.markdown(
            f"""
        <div style="background: linear-gradient(135deg, #74b9ff 0%, #0984e3 100%);
                    color: white; padding: 1.5rem; border-radius: 15px; text-align: center; margin: 1rem 0;">
            <h4>ã‚¹ãƒ†ãƒƒãƒ— {total_points + 1}</h4>
            <p><strong>æ¬¡ã«ã‚¯ãƒªãƒƒã‚¯:</strong> {current_name}</p>
            <div class="progress-indicator" style="width: {((total_points * 3 + current_step) / 15) * 100}%;"></div>
        </div>
        """,
            unsafe_allow_html=True,
        )

        # 3ã¤ã®ç”»åƒã‚’æ¨ªä¸¦ã³ã§è¡¨ç¤º
        annotation_col1, annotation_col2, annotation_col3 = st.columns(3, gap="large")

        # ç”»åƒè¡¨ç¤ºã¨ã‚¯ãƒªãƒƒã‚¯å‡¦ç†
        for i, (key, name) in enumerate(zip(image_keys, image_names)):
            with [annotation_col1, annotation_col2, annotation_col3][i]:

                plotted_image = draw_manual_points(
                    images[key], st.session_state.manual_points[key]
                )

                if i == current_step:
                    st.success(f" {name} (ã‚¯ãƒªãƒƒã‚¯å¯¾è±¡)")
                    # ã‚¯ãƒªãƒƒã‚¯å¯èƒ½ãªç”»åƒ
                    display_width = 400
                    image_height, image_width = plotted_image.shape[:2]
                    aspect_ratio = image_height / image_width
                    display_height = int(display_width * aspect_ratio)

                    coords = streamlit_image_coordinates(
                        plotted_image,
                        key=f"coords_{key}_{st.session_state.current_point_index}",
                        width=display_width,
                        height=display_height,
                    )

                    if coords is not None:
                        # åº§æ¨™ã‚’ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒã‚µã‚¤ã‚ºã«ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
                        scale_x = image_width / display_width
                        scale_y = image_height / display_height
                        original_x = coords["x"] * scale_x
                        original_y = coords["y"] * scale_y

                        st.session_state.manual_points[key].append(
                            [original_x, original_y]
                        )

                        # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã«é€²ã‚€
                        if current_step < 2:
                            st.session_state.current_image_step += 1
                        else:
                            st.session_state.current_image_step = 0
                            st.session_state.current_point_index += 1
                        st.rerun()
                else:
                    st.info(f" {name}")
                    st.image(plotted_image, use_container_width=True)

                # ç¾åœ¨ã®ç‚¹æ•°ã‚’è¡¨ç¤º
                point_count = len(st.session_state.manual_points[key])
                st.markdown(f"**é…ç½®æ¸ˆã¿:** `{point_count}ç‚¹`")
                st.markdown("</div>", unsafe_allow_html=True)

        # ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ‘ãƒãƒ«
        st.markdown("###  ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ‘ãƒãƒ«")
        btn_col1, btn_col2, btn_col3, btn_col4 = st.columns(4, gap="medium")

        with btn_col1:
            if st.button(" å‰ã®ç‚¹ã«æˆ»ã‚‹", use_container_width=True):
                if st.session_state.current_image_step > 0:
                    st.session_state.current_image_step -= 1
                elif total_points > 0:
                    for key in image_keys:
                        if st.session_state.manual_points[key]:
                            st.session_state.manual_points[key].pop()
                    st.session_state.current_image_step = 2
                    if st.session_state.current_point_index > 0:
                        st.session_state.current_point_index -= 1
                st.rerun()

        with btn_col2:
            if st.button(" å…¨ã¦å‰Šé™¤", use_container_width=True):
                st.session_state.manual_points = {"base": [], "comp1": [], "comp2": []}
                st.session_state.current_point_index = 0
                st.session_state.current_image_step = 0
                st.rerun()

        with btn_col3:
            if st.button(" ã‚¹ã‚­ãƒƒãƒ—", use_container_width=True):
                if current_step < 2:
                    st.session_state.current_image_step += 1
                else:
                    st.session_state.current_image_step = 0
                    st.session_state.current_point_index += 1
                st.rerun()

        # é€²æ—è¡¨ç¤º
        points_counts = [len(st.session_state.manual_points[k]) for k in image_keys]
        min_points = min(points_counts)

        st.markdown("###  é€²æ—çŠ¶æ³")
        progress_col1, progress_col2, progress_col3 = st.columns(3, gap="large")

        for i, (count, name) in enumerate(zip(points_counts, image_names)):
            with [progress_col1, progress_col2, progress_col3][i]:
                st.metric(
                    name.replace(" ", "").replace(" ", "").replace(" ", ""),
                    f"{count}ç‚¹",
                )
                # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
                progress_percent = min(100, (count / 5) * 100) if count <= 5 else 100
                st.markdown(
                    f"""
                <div style="background: #e9ecef; border-radius: 10px; overflow: hidden; margin-top: 0.5rem;">
                    <div style="background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); 
                                width: {progress_percent}%; height: 8px; transition: width 0.3s ease;"></div>
                </div>
                """,
                    unsafe_allow_html=True,
                )
                st.markdown("</div>", unsafe_allow_html=True)

        # é¡ä¼¼åº¦è¨ˆç®—ãƒœã‚¿ãƒ³
        if min_points >= 3 and len(set(points_counts)) == 1:
            with btn_col4:
                if st.button(" é¡ä¼¼åº¦è¨ˆç®—", use_container_width=True, type="primary"):
                    st.session_state.show_manual_results = True
                    base_points = np.array(st.session_state.manual_points["base"])
                    comp1_points = np.array(st.session_state.manual_points["comp1"])
                    comp2_points = np.array(st.session_state.manual_points["comp2"])

                    # é¸æŠã•ã‚ŒãŸæŒ‡æ¨™ã«å¿œã˜ã¦é¡ä¼¼åº¦è¨ˆç®—
                    def get_similarity_function(metric):
                        if "ç·åˆè©•ä¾¡" in metric:
                            return calculate_combined_similarity
                        elif "ã‚³ã‚µã‚¤ãƒ³" in metric:
                            return calculate_cosine_similarity
                        elif "ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰" in metric:
                            return calculate_normalized_euclidean_similarity
                        elif "ãƒã‚¦ã‚¹ãƒ‰ãƒ«ãƒ•" in metric:
                            return calculate_hausdorff_similarity
                        else:  # ãƒ—ãƒ­ã‚¯ãƒ©ã‚¹ãƒ†ã‚¹
                            return calculate_procrustes_similarity

                    similarity_func = get_similarity_function(similarity_metric)
                    st.session_state.manual_similarity1 = similarity_func(
                        base_points, comp1_points
                    )
                    st.session_state.manual_similarity2 = similarity_func(
                        base_points, comp2_points
                    )

        elif min_points < 3:
            st.markdown(
                f"""
            <div style="background: #fff3cd; padding: 1rem; border-radius: 10px; margin: 1rem 0;">
                <strong> ãƒ’ãƒ³ãƒˆ:</strong> å„ç”»åƒã«æœ€ä½3ç‚¹ãšã¤é…ç½®ã—ã¦ãã ã•ã„ã€‚ç¾åœ¨: {min_points}ç‚¹
            </div>
            """,
                unsafe_allow_html=True,
            )
        elif len(set(points_counts)) != 1:
            st.warning(
                f" å…¨ã¦ã®ç”»åƒã«åŒã˜æ•°ã®ç‚¹ã‚’é…ç½®ã—ã¦ãã ã•ã„ã€‚ç¾åœ¨: åŸºæº–{points_counts[0]}ç‚¹, æ¯”è¼ƒ1{points_counts[1]}ç‚¹, æ¯”è¼ƒ2{points_counts[2]}ç‚¹"
            )

        st.markdown("</div>", unsafe_allow_html=True)

        # çµæœè¡¨ç¤º
        if (
            hasattr(st.session_state, "show_manual_results")
            and st.session_state.show_manual_results
        ):

            similarity1 = st.session_state.manual_similarity1
            similarity2 = st.session_state.manual_similarity2

            # æŒ‡æ¨™ã«å¿œã˜ã¦ãƒ˜ãƒ«ãƒ—ãƒ†ã‚­ã‚¹ãƒˆã‚’å¤‰æ›´
            is_procrustes = "ãƒ—ãƒ­ã‚¯ãƒ©ã‚¹ãƒ†ã‚¹" in similarity_metric
            help_text = f"{similarity_metric}ï¼ˆå€¤ãŒ{'å°ã•ã„' if is_procrustes else 'å¤§ãã„'}ã»ã©é¡ä¼¼ï¼‰"

            # æ‰‹å‹•æ³¨é‡ˆçµæœã‚»ã‚¯ã‚·ãƒ§ãƒ³
            st.markdown('<div class="result-section">', unsafe_allow_html=True)
            st.markdown("###  æ‰‹å‹•æ³¨é‡ˆã«ã‚ˆã‚‹é¡ä¼¼åº¦åˆ†æçµæœ")

            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
            result_col1, result_col2, result_col3 = st.columns(3, gap="large")

            with result_col1:
                st.metric(" åŸºæº– vs æ¯”è¼ƒ1", f"{similarity1:.4f}", help=help_text)
                st.markdown("</div>", unsafe_allow_html=True)

            with result_col2:
                st.metric(" åŸºæº– vs æ¯”è¼ƒ2", f"{similarity2:.4f}", help=help_text)
                st.markdown("</div>", unsafe_allow_html=True)

            with result_col3:
                difference = abs(similarity1 - similarity2)
                st.metric(
                    " é¡ä¼¼åº¦ã®å·®", f"{difference:.4f}", help="2ã¤ã®é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ã®å·®"
                )
                st.markdown("</div>", unsafe_allow_html=True)

            # å‹è€…ã®ç™ºè¡¨ï¼ˆæŒ‡æ¨™ã«å¿œã˜ã¦åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ã‚’å¤‰æ›´ï¼‰
            if (is_procrustes and similarity1 < similarity2) or (
                not is_procrustes and similarity1 > similarity2
            ):
                winner = "æ¯”è¼ƒç”»åƒ1(äººç‰©A)"
                winner_score = similarity1
                st.markdown(
                    f"""
                <div class="winner-card">
                    <h3> æ‰‹å‹•åˆ†æçµæœ</h3>
                    <h2> {winner}</h2>
                    <p>ãŒåŸºæº–ç”»åƒã«ã‚ˆã‚Šé¡ä¼¼ã—ã¦ã„ã¾ã™</p>
                    <p><strong>ã‚¹ã‚³ã‚¢å·®: {difference:.4f}</strong></p>
                </div>
                """,
                    unsafe_allow_html=True,
                )
            else:
                winner = "æ¯”è¼ƒç”»åƒ2(äººç‰©B)"
                winner_score = similarity2
                st.markdown(
                    f"""
                <div class="winner-card">
                    <h3> æ‰‹å‹•åˆ†æçµæœ</h3>
                    <h2> {winner}</h2>
                    <p>ãŒåŸºæº–ç”»åƒã«ã‚ˆã‚Šé¡ä¼¼ã—ã¦ã„ã¾ã™</p>
                    <p><strong>ã‚¹ã‚³ã‚¢å·®: {difference:.4f}</strong></p>
                </div>
                """,
                    unsafe_allow_html=True,
                )

            # ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³çµæœã®è¡¨ç¤º
            st.markdown("###  ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³çµæœæ¯”è¼ƒ")
            final_col1, final_col2, final_col3, final_col4 = st.columns(4, gap="medium")

            with final_col1:
                st.markdown("####  åŸºæº–ç”»åƒ")
                base_annotated = draw_manual_points(
                    images["base"], st.session_state.manual_points["base"]
                )
                st.image(base_annotated, caption="åŸºæº–", use_container_width=True)
                st.markdown("</div>", unsafe_allow_html=True)

            with final_col2:
                st.markdown("####  æ¯”è¼ƒç”»åƒ1(äººç‰©A)")
                comp1_annotated = draw_manual_points(
                    images["comp1"], st.session_state.manual_points["comp1"]
                )
                st.image(
                    comp1_annotated,
                    caption=f"é¡ä¼¼åº¦: {similarity1:.4f}",
                    use_container_width=True,
                )
                if winner == "æ¯”è¼ƒç”»åƒ1(äººç‰©A)":
                    st.success(" ã‚ˆã‚Šé¡ä¼¼")
                else:
                    st.info(" é¡ä¼¼åº¦ä½")
                st.metric(
                    label=" åŸºæº– vs æ¯”è¼ƒ1",
                    value=f"{similarity1:.4f}",
                    help=help_text,
                )
                st.markdown("</div>", unsafe_allow_html=True)

            with final_col3:
                st.markdown("####  æ¯”è¼ƒç”»åƒ2(äººç‰©B)")
                comp2_annotated = draw_manual_points(
                    images["comp2"], st.session_state.manual_points["comp2"]
                )
                st.image(
                    comp2_annotated,
                    caption=f"é¡ä¼¼åº¦: {similarity2:.4f}",
                    use_container_width=True,
                )
                if winner == "æ¯”è¼ƒç”»åƒ2(äººç‰©B)":
                    st.success(" ã‚ˆã‚Šé¡ä¼¼")
                else:
                    st.info(" é¡ä¼¼åº¦ä½")
                st.metric(
                    label=" åŸºæº– vs æ¯”è¼ƒ2",
                    value=f"{similarity2:.4f}",
                    help=help_text,
                )
                st.markdown("</div>", unsafe_allow_html=True)

            with final_col4:
                st.markdown("####  åˆ†æã‚µãƒãƒªãƒ¼")
                st.markdown(f"æœ€é¡ä¼¼:{winner}")
                st.markdown(f"ã‚¹ã‚³ã‚¢:{winner_score:.4f}")
                st.markdown(f"ç·ãƒã‚¤ãƒ³ãƒˆ:{min_points}ç‚¹")
                st.markdown(
                    f"åŸºæº–ç”»åƒ:{len(st.session_state.manual_points['base'])}ç‚¹"
                )
                st.markdown(
                    f"æ¯”è¼ƒç”»åƒ1:{len(st.session_state.manual_points['comp1'])}ç‚¹"
                )
                st.markdown(
                    f"æ¯”è¼ƒç”»åƒ2(äººç‰©B):{len(st.session_state.manual_points['comp2'])}ç‚¹"
                )

                if st.button(" çµæœã‚’ã‚¯ãƒªã‚¢", use_container_width=True):
                    st.session_state.show_manual_results = False
                    st.rerun()
                st.markdown("</div>", unsafe_allow_html=True)

            st.markdown("</div>", unsafe_allow_html=True)

    else:
        st.markdown(
            """
        <div style="background: linear-gradient(135deg, #ffeaa7 0%, #fab1a0 100%); color: #31333F;
                    padding: 2rem; border-radius: 15px; text-align: center; margin: 2rem 0;">
            <h3> æ‰‹å‹•ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³</h3>
            <p>3ã¤ã®ç”»åƒã‚’ã™ã¹ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‹ã‚‰æ‰‹å‹•ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã¦ãã ã•ã„</p>
            <p><strong> ãƒ’ãƒ³ãƒˆ:</strong> åŒã˜ç‰¹å¾´ç‚¹ï¼ˆä¾‹ï¼šç›®ã®è§’ã€é¼»ã®å…ˆç«¯ã€å£ã®è§’ãªã©ï¼‰ã‚’å„ç”»åƒã§åŒã˜é †ç•ªã§ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„</p>
        </div>
        """,
            unsafe_allow_html=True,
        )


def draw_manual_points(image, points):
    if not points:
        return image

    plotted_image = image.copy()
    height, width = image.shape[:2]
    point_size = max(4, min(width, height) // 120)

    for i, point in enumerate(points):
        x, y = int(point[0]), int(point[1])

        # ãƒ¢ãƒ€ãƒ³ãªã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆ
        colors = [
            (255, 107, 107),  # ãƒ©ã‚¤ãƒˆãƒ¬ãƒƒãƒ‰
            (78, 205, 196),  # ã‚¿ãƒ¼ã‚³ã‚¤ã‚º
            (69, 90, 100),  # ãƒ€ãƒ¼ã‚¯ã‚°ãƒ¬ãƒ¼
            (255, 195, 18),  # ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¤ã‚¨ãƒ­ãƒ¼
            (156, 136, 255),  # ãƒ‘ãƒ¼ãƒ—ãƒ«
            (26, 188, 156),  # ã‚¨ãƒ¡ãƒ©ãƒ«ãƒ‰
            (241, 196, 15),  # ã‚µãƒ³ãƒ•ãƒ©ãƒ¯ãƒ¼
            (231, 76, 60),  # ã‚¢ãƒªã‚¶ãƒªãƒ³
        ]

        color = colors[i % len(colors)]

        # å¤–å´ã®ç™½ã„ãƒãƒ­ãƒ¼åŠ¹æœ
        cv2.circle(plotted_image, (x, y), point_size + 3, (255, 255, 255), -1)
        # å½±åŠ¹æœï¼ˆé€æ˜åº¦ã¯ä½¿ãˆãªã„ã®ã§è–„ã„ã‚°ãƒ¬ãƒ¼ã§ä»£ç”¨ï¼‰
        cv2.circle(plotted_image, (x + 1, y + 1), point_size + 2, (200, 200, 200), -1)
        # ãƒ¡ã‚¤ãƒ³ãƒã‚¤ãƒ³ãƒˆ
        cv2.circle(plotted_image, (x, y), point_size, color, -1)
        # å†…å´ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆ
        cv2.circle(
            plotted_image, (x - 1, y - 1), max(1, point_size // 2), (255, 255, 255), -1
        )

        # ãƒã‚¤ãƒ³ãƒˆç•ªå·è¡¨ç¤ºï¼ˆæ”¹è‰¯ç‰ˆï¼‰
        font_scale = max(0.6, min(width, height) / 800)
        text = str(i + 1)
        text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, 2)[0]

        # ãƒ†ã‚­ã‚¹ãƒˆèƒŒæ™¯
        text_x = x + point_size + 8
        text_y = y + point_size // 2

        # èƒŒæ™¯çŸ©å½¢
        bg_padding = 4
        cv2.rectangle(
            plotted_image,
            (text_x - bg_padding, text_y - text_size[1] - bg_padding),
            (text_x + text_size[0] + bg_padding, text_y + bg_padding),
            (255, 255, 255),
            -1,
        )
        cv2.rectangle(
            plotted_image,
            (text_x - bg_padding, text_y - text_size[1] - bg_padding),
            (text_x + text_size[0] + bg_padding, text_y + bg_padding),
            color,
            2,
        )

        # ãƒ†ã‚­ã‚¹ãƒˆ
        cv2.putText(
            plotted_image,
            text,
            (text_x, text_y),
            cv2.FONT_HERSHEY_SIMPLEX,
            font_scale,
            color,
            2,
        )

    # ç·ãƒã‚¤ãƒ³ãƒˆæ•°ã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤ºï¼ˆæ”¹è‰¯ç‰ˆï¼‰
    if points:
        # èƒŒæ™¯ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³é¢¨ã®ãƒãƒ¼
        overlay = plotted_image.copy()
        cv2.rectangle(overlay, (0, 0), (width, 50), (0, 0, 0), -1)
        cv2.addWeighted(plotted_image, 0.7, overlay, 0.3, 0, plotted_image)

        # ãƒã‚¤ãƒ³ãƒˆæ•°è¡¨ç¤º
        status_text = f"Points: {len(points)} | Status: Active"
        cv2.putText(
            plotted_image,
            status_text,
            (15, 30),
            cv2.FONT_HERSHEY_DUPLEX,
            0.8,
            (255, 255, 255),
            2,
        )
        cv2.putText(
            plotted_image,
            status_text,
            (15, 30),
            cv2.FONT_HERSHEY_DUPLEX,
            0.8,
            (78, 205, 196),
            1,
        )

    return plotted_image


if __name__ == "__main__":
    main()
